# Анализ текущего кода

## simple_vad_service.py

### Текущая логика VAD (строки 33-277, 317-390)
- `SimpleVADService` инициализируется с тайм‑аутами из `.env` (`VAD_SILENCE_TIMEOUT=2.0`, `VAD_MIN_RECORDING_TIME=1.0`, `VAD_MAX_RECORDING_TIME=15.0`) и заносит состояние мониторинга в `self.active_monitors` (строки 33-107).
- `update_activity()` (строки 147-167) просто сбрасывает `last_activity` и `silence_start`; отдельного счетчика `activity_updates` нет – фактически логика не отслеживает, насколько часто канал «шевелится».
- Основной цикл `_monitor_silence()` (строки 169-237) раз в 100 мс вычисляет `recording_duration` (строка 184) и `time_since_activity` (строка 185), сравнивая их с `max_duration` (строки 189-195) и адаптивным порогом тишины (строки 207-210). При отсутствии обновлений `last_activity` больше `silence_timeout_threshold` фиксируется начало тишины (строки 214-216), а при достижении `required_silence` вызывается `_finish_recording()` (строки 223-226, 239-277).
- Метод `record_until_silence_with_soft_window()` (строки 317-390) режет речь на окна (`window_seconds` из `.env`, по умолчанию 5 c), для каждого окна запускает `start_monitoring()` с `max_duration_override=window_seconds` (строки 358-364) и ждёт `finished_future` от `_finish_recording()` (строки 370-377).

### Проблема: Преждевременное прерывание (строки 213-226)
- Текущее значение: `VAD_SILENCE_TIMEOUT = 2.0` секунды (строки 410-412).
- Проблема: `update_activity()` вообще не вызывается во время записи окна – единственные вызовы находятся уже после завершения ASR (`process_user_speech_optimized`, строки 368-381; soft-window блок 1801-1803). Пока пользователь говорит, `last_activity` остаётся равным `start_time`, и через ~2 секунды `_monitor_silence()` считает, что наступила тишина.
- Где срабатывает: ветка `silence_duration >= required_silence` в `_monitor_silence()` (строки 223-226) → `_finish_recording()` завершает запись с причиной `silence_detected`.
- Симптом из логов: в момент обрыва появляется `VAD: Окончание речи детектировано…` (строка 224) сразу после `VAD: Тишина обнаружена…` (строка 216), хотя фактической тишины не было.

### Адаптивный таймаут (строки 205-211)
- Текущая реализация: для первой трети окна `silence_timeout_threshold = silence_timeout * 1.5`, затем возвращается к `silence_timeout` (строки 207-210). Однако фактический порог `required_silence` берётся как `min(silence_timeout, silence_timeout_threshold)` (строка 220), поэтому даже при расчёте «адаптивного» значения минимальный тайм‑аут остаётся 2 секунды.
- Недостаток: без реальных `update_activity()` адаптивное окно не спасает – для soft-window сегмента в 5 секунд пауза всё равно фиксируется через 2 секунды и запись обрывается, хотя пользователь продолжает говорить. Дополнительно отсутствует логика учёта `activity_updates`, которую требовали спецификации.

## parallel_tts.py

### Архитектура очереди (строки 29-170, 186-238)
- Параметры `TTS_PARALLEL_WORKERS` (строка 42, по умолчанию 3) и `AUDIO_BUFFER_SIZE` (строка 43, по умолчанию 2) читаются из `.env`, но дальше в коде не используются.
- `process_chunk_immediate()` складывает все TTS задачи в `self.tts_tasks[channel_id]` и сразу запускает `async` синтез (строки 60-95).
- `_synthesize_chunk_async()` после `await grpc_tts.synthesize_chunk_fast()` вызывает `_enqueue_playback()` (строки 124-156).
- `_enqueue_playback()` поддерживает одну очередь `playback_queues[channel_id]`, сразу сортирует её и, если канал не занят, запускает `_process_playback_queue()` (строки 157-170). Реальной «глубины буфера» нет – `self.audio_buffer_size` никак не задействован.
- `_process_playback_queue()` берёт первый элемент, требует строгой последовательности `chunk_num` начиная с 1 (строки 192-218) и сразу отправляет его в `_play_audio_chunk()` (строки 219-221). Финальные чанки помечены `chunk_number=999` (см. `stasis_handler_optimized.py` строки 702-707), из-за чего цикл зависает в ожидании «следующего» номера.

### Проблема: Buffer underrun (строки 215-284)
- Где возникает: во время `_play_audio_chunk()` – после сохранения файла и вызова `ari_client.play_sound()` (строки 239-283) очередь немедленно освобождается (строка 216). Никакого ожидания на наполнение очереди нет, а `audio_buffer_size` не ограничивает запуск воспроизведения.
- Размер буфера: `AUDIO_BUFFER_SIZE` читается (строка 43) как 2, но нигде не учитывается.
- Параллельные воркеры: `TTS_PARALLEL_WORKERS = 3` (строка 42), но созданный `ThreadPoolExecutor` (строка 46) нигде не используется – фактически ограничений по одновременному синтезу нет.
- Почему underrun: воспроизведение стартует немедленно на первом же чанке, а следующий чанк часто ещё не успел синтезироваться или записаться на диск. В момент, когда Asterisk дочитывает WAV, в `playback_queues[channel_id]` уже пусто, поэтому движок получает «дыры» и фиксирует Buffer underrun. Дополнительно `await asyncio.sleep(max(0.5, estimated_duration))` (строка 281) лишь имитирует продолжительность, но не гарантирует, что следующий файл уже готов.

### Воспроизведение аудио (строки 239-291)
- WAV-файлы пишутся в `sounds/<lang>` и сразу запускаются через ARI (строки 254-273).
- После старта playback код просто `await asyncio.sleep(...)` (строки 279-283); никаких событий завершения, проверки очереди или буферизации не выполняется.
- Отсутствуют проверки на «блокировку» после barge-in – `block_enqueue_until`/`barge_in_until`, которые модуль пытается выставлять из `stasis_handler`, в самом классе не определены.

## stasis_handler_optimized.py

### Обработка ChannelTalkingStarted/Finished (строки 1343-1571)
- События маршрутизируются в `handle_event()` (строки 1343-1360). `ChannelTalkingFinished` не обрабатывается вообще – предусмотрена только реакция на `ChannelTalkingStarted` (строки 1532-1571).
- `handle_playback_started()` (строки 1387-1454) считает playback‑ы, поднимает флаги `is_speaking`, `last_speak_started_at` и увеличивает `playback_count`. Именно `last_speak_started_at` используется для гварда в `handle_talking_started()`.
- `handle_playback_finished()` (строки 1456-1529) сбрасывает `is_speaking`, проверяет активные TTS задачи (`parallel_tts.tts_tasks` и `playback_queues`) и только при их отсутствии запускает новую запись (`start_user_recording`).
- `handle_talking_started()` (строки 1532-1571) реагирует на событие как на barge-in: игнорирует первые два playback-а (`playback_count < 2`), вводит «защиту» 800 мс (`since_start < 800`), затем останавливает TTS и инициирует запись. Событий `ChannelTalkingFinished` для синхронизации с VAD/записью нет – дальнейшая логика целиком полагается на VAD.
- Тайминги: `last_speak_started_at` обновляется на старте каждого playback (строка 1412), guard в `handle_talking_started()` использует разницу в миллисекундах (строки 1554-1556). Перезапуск VAD из `ParallelTTSProcessor.on_tts_idle` возможен только когда очередь и задачи опустели (строки 148-167 внутри инициализации сервиса).

## ИТОГОВЫЙ ВЫВОД
- Главная причина underrun: очередь TTS не поддерживает буферизацию – `AUDIO_BUFFER_SIZE` и `TTS_PARALLEL_WORKERS` не участвуют в логике, а `_process_playback_queue()` (строки 215-284) запускает воспроизведение немедленно. Пока следующий чанк синтезируется/записывается, Asterisk доходит до конца текущего WAV и остаётся без данных, что приводит к Buffer underrun.
- Главная причина VAD-обрыва: `_monitor_silence()` (строки 169-226) полагается на регулярные `update_activity()`, но эти обновления выполняются только после завершения ASR и не поступают во время записи. В результате VAD уже через `VAD_SILENCE_TIMEOUT` (~2 секунды) считает, что наступила тишина, и преждевременно завершает запись.
- На что фокусироваться при исправлении:
  - Внедрить реальный счётчик активности/обновление `last_activity` во время записи (например, через события Asterisk или поток PCM) и пересмотреть адаптивный тайм-аут в VAD.
  - В `ParallelTTSProcessor` реализовать предзаполнение очереди до `audio_buffer_size`, учитывать финальные чанки (`chunk_number=999`), а также синхронизировать воспроизведение с фактическим окончанием playback вместо `sleep`.
  - Рассмотреть обработку `ChannelTalkingFinished` и более точную синхронизацию VAD с событиями `ChannelTalkingStarted/Finished`, чтобы не полагаться только на тайм-ауты.
